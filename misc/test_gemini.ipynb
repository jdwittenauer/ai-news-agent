{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4beb3-0b80-4b03-812b-f480b01c38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.google.dev/gemini-api/docs/quickstart\n",
    "# https://ai.google.dev/gemini-api/docs/rate-limits\n",
    "\n",
    "FREE_MODELS = [\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-flash-lite-preview-06-17\",\n",
    "    \"gemini-2.0-flash\",\n",
    "    \"gemini-2.0-flash-lite\",\n",
    "    \"gemma-3-27b-it\",\n",
    "    \"gemma-3n-e4b-it\",\n",
    "    \"text-embedding-004\"\n",
    "]\n",
    "\n",
    "LIST_MODELS = False\n",
    "\n",
    "import httpx\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "if LIST_MODELS:\n",
    "    for model in client.models.list():\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c848e3a9-a780-4703-bd59-09087ef29f8e",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def64a7a-fe8b-43f4-aa6f-49e34a827eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemma-3-27b-it\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=1.0\n",
    "    ),\n",
    "    contents=[\"Explain how AI works in a few words\"]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1d51d-0f91-401f-bd50-46d82a66e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemma-3-27b-it\",\n",
    "    contents=[\"Explain how AI works in a few words\"]\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f51760-acb4-4319-8511-19e23677e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System instructions\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a cat. Your name is Neko.\"\n",
    "    ),\n",
    "    contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf01734-e31d-4f20-a94c-989ed411c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat\n",
    "chat = client.chats.create(model=\"gemma-3-27b-it\")\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(f\"{message.role}:\")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afdb82b-dd93-4118-ad94-714c727ba2cd",
   "metadata": {},
   "source": [
    "### Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7444ff-da53-4c5a-8976-9d9b04365da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n",
    "image_bytes = requests.get(image_path).content\n",
    "image = types.Part.from_bytes(\n",
    "  data=image_bytes, mime_type=\"image/jpeg\"\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemma-3-27b-it\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=1.0\n",
    "    ),\n",
    "    contents=[image, \"Tell me about this image\"]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01122287-999f-4e71-a60a-8297f557996f",
   "metadata": {},
   "source": [
    "### Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d053e5-833e-41ed-857f-07344d84ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Provide a list of 3 famous physicists and their key contributions\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=1024, include_thoughts=True)\n",
    "        # Turn off thinking:\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "        # Turn on dynamic thinking:\n",
    "        # thinking_config=types.ThinkingConfig(thinking_budget=-1)\n",
    "    )\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca87a4e-0461-45b2-b9e5-b3bfd55671c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in response.candidates[0].content.parts:\n",
    "    if not part.text:\n",
    "        continue\n",
    "    if part.thought:\n",
    "        print(\"Thought summary:\")\n",
    "        print(part.text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f848c-8c68-40f7-8714-1a51d69cc639",
   "metadata": {},
   "source": [
    "### Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6be8ac-8863-49bc-bafa-e6e210839e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recipe(BaseModel):\n",
    "    recipe_name: str\n",
    "    ingredients: list[str]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"List a few popular cookie recipes, and include the amounts of ingredients.\",\n",
    "    config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": list[Recipe],\n",
    "    },\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ebd2f-1a3b-4462-bebc-a3f81e6cd99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recipes: list[Recipe] = response.parsed\n",
    "len(my_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74558021-a707-4144-bf28-9d9ae25682c1",
   "metadata": {},
   "source": [
    "### Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5d069-daf4-4040-8295-ac692bfe32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_function = {\n",
    "    \"name\": \"get_current_temperature\",\n",
    "    \"description\": \"Gets the current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city name, e.g. San Francisco\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "tools = types.Tool(function_declarations=[weather_function])\n",
    "config = types.GenerateContentConfig(tools=[tools])\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"What's the temperature in London?\",\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    print(f\"Function to call: {function_call.name}\")\n",
    "    print(f\"Arguments: {function_call.args}\")\n",
    "    #  In a real app, you would call your function here:\n",
    "    #  result = get_current_temperature(**function_call.args)\n",
    "else:\n",
    "    print(\"No function call found in the response.\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6389d-506b-415e-b7a5-46a8089bc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_forecast(location: str) -> dict:\n",
    "    \"\"\"Gets the current weather temperature for a given location.\"\"\"\n",
    "    print(f\"Tool Call: get_weather_forecast(location={location})\")\n",
    "    print(\"Tool Response: {'temperature': 25, 'unit': 'celsius'}\")\n",
    "    return {\"temperature\": 25, \"unit\": \"celsius\"}\n",
    "\n",
    "def set_thermostat_temperature(temperature: int) -> dict:\n",
    "    \"\"\"Sets the thermostat to a desired temperature.\"\"\"\n",
    "    print(f\"Tool Call: set_thermostat_temperature(temperature={temperature})\")\n",
    "    print(\"Tool Response: {'status': 'success'}\")\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "config = types.GenerateContentConfig(\n",
    "    tools=[get_weather_forecast, set_thermostat_temperature]\n",
    ")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"If it's warmer than 20°C in London, set the thermostat to 20°C, otherwise set it to 18°C.\",\n",
    "    config=config,\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce83218-2dee-4054-a986-57cb1e719a56",
   "metadata": {},
   "source": [
    "### Document Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f5d55-072c-430c-909e-babb4548cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"\n",
    "doc_data = httpx.get(doc_url).content\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(data=doc_data, mime_type='application/pdf'),\n",
    "        \"Summarize this document\"\n",
    "    ]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68acee93-382e-41c5-a611-d4fa19dc6c2d",
   "metadata": {},
   "source": [
    "### Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362b5cc-bca1-4e36-8df3-cef9c1e825bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "What is the sum of the first 50 prime numbers? Generate and run code\n",
    "for the calculation, and make sure you get all 50.\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[types.Tool(code_execution=types.ToolCodeExecution)]\n",
    "    )\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56917e4-cd0d-4a45-9edf-615fecbc566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in response.candidates[0].content.parts:\n",
    "    if part.text is not None:\n",
    "        print(part.text)\n",
    "    if part.executable_code is not None:\n",
    "        print(part.executable_code.code)\n",
    "    if part.code_execution_result is not None:\n",
    "        print(part.code_execution_result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ebbc7d-8771-465a-a343-b236b0f0df8e",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37276bf5-471a-4340-ae6f-255d23b26c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = types.ToolConfig(\n",
    "    function_calling_config=types.FunctionCallingConfig(\n",
    "        mode=\"ANY\", allowed_function_names=[\"get_current_temperature\"]\n",
    "    )\n",
    ")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"Who won the NBA Finals 2025?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        tool_config=types.ToolConfig(\n",
    "            function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc81fcd-1fdd-4f8b-b600-c9a749c91e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_citations(response):\n",
    "    text = response.text\n",
    "    supports = response.candidates[0].grounding_metadata.grounding_supports\n",
    "    chunks = response.candidates[0].grounding_metadata.grounding_chunks\n",
    "\n",
    "    # Sort supports by end_index in descending order to avoid shifting issues when inserting.\n",
    "    sorted_supports = sorted(supports, key=lambda s: s.segment.end_index, reverse=True)\n",
    "\n",
    "    for support in sorted_supports:\n",
    "        end_index = support.segment.end_index\n",
    "        if support.grounding_chunk_indices:\n",
    "            # Create citation string like [1](link1)[2](link2)\n",
    "            citation_links = []\n",
    "            for i in support.grounding_chunk_indices:\n",
    "                if i < len(chunks):\n",
    "                    uri = chunks[i].web.uri\n",
    "                    citation_links.append(f\"[{i + 1}]({uri})\")\n",
    "\n",
    "            citation_string = \", \".join(citation_links)\n",
    "            text = text[:end_index] + citation_string + text[end_index:]\n",
    "\n",
    "    return text\n",
    "\n",
    "text_with_citations = add_citations(response)\n",
    "print(text_with_citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabcf70-48b3-4468-8a76-2095ade67702",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cdfa1-72ee-4244-a46f-89f25973d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.models.embed_content(\n",
    "    model=\"text-embedding-004\",\n",
    "    contents=[\"What is the meaning of life?\"]\n",
    ")\n",
    "print(result.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7c130-b412-42a5-ad5c-e31f79212771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 - AI",
   "language": "python",
   "name": "python_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
