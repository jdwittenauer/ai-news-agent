{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bccd8-b63d-480e-8f9b-e6022a36272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoProcessor,\n",
    "    AutoTokenizer,\n",
    "    Gemma3ForConditionalGeneration\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "embed_model_id = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "reranker_model_id = \"Qwen/Qwen3-Reranker-0.6B\"\n",
    "llm_model_id = \"google/gemma-3-4b-it\"\n",
    "image_gen_model_id = \"stabilityai/sdxl-turbo\"\n",
    "DEVICE = \"cuda:0\"\n",
    "DOWNLOAD_REPOS = False\n",
    "\n",
    "if DOWNLOAD_REPOS:\n",
    "    # Saved to ~/.cache/huggingface/hub\n",
    "    load_dotenv()\n",
    "    login(token=os.getenv(\"HF_TOKEN\"))\n",
    "    snapshot_download(embed_model_id)\n",
    "    snapshot_download(reranker_model_id)\n",
    "    snapshot_download(llm_model_id)\n",
    "    snapshot_download(image_gen_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae51b9a-c580-4f5d-9116-b51c4d74e53e",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045e3c3-4511-494c-addf-ecd4c4960d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer(\n",
    "    embed_model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.float16, \"attn_implementation\": \"flash_attention_2\", \"device_map\": \"auto\"},\n",
    "    tokenizer_kwargs={\"padding_side\": \"left\"},\n",
    ")\n",
    "\n",
    "queries = [\n",
    "    \"What is the capital of China?\",\n",
    "    \"Explain gravity\"\n",
    "]\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other.\"\n",
    "]\n",
    "\n",
    "query_embeddings = embed_model.encode(queries, prompt_name=\"query\")\n",
    "document_embeddings = embed_model.encode(documents)\n",
    "similarity = embed_model.similarity(query_embeddings, document_embeddings)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5c7d6-af71-4171-b005-b24500b33709",
   "metadata": {},
   "source": [
    "### Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b43d19a-b9f6-4a9c-bc6f-9a7660188d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model_id)\n",
    "reranker_model = AutoModelForCausalLM.from_pretrained(\n",
    "    reranker_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").eval()\n",
    "\n",
    "def get_rerank_scores(tokenizer, model, pairs):\n",
    "    inputs = tokenizer(\n",
    "        pairs, padding=True, truncation='longest_first', return_tensors='pt', return_attention_mask=False, max_length=4096\n",
    "    )\n",
    "    for key in inputs:\n",
    "        inputs[key] = inputs[key].to(model.device)\n",
    "    with torch.no_grad():\n",
    "        scores = model(**inputs).logits[:, -1, :]\n",
    "    return scores\n",
    "\n",
    "pairs = [\n",
    "    [\"What is the capital of China?\", \"The capital of China is Beijing.\"],\n",
    "    [\"What is the capital of China?\", \"Gravity is a force that attracts two bodies towards each other.\"]\n",
    "]\n",
    "\n",
    "scores = get_rerank_scores(reranker_tokenizer, reranker_model, pairs)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9efea9-752d-4abf-a2ff-9e259a61b52a",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133bb13f-2b3e-450b-b412-43386fe302f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_processor = AutoProcessor.from_pretrained(llm_model_id)\n",
    "llm_model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    llm_model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\"\n",
    ").eval()\n",
    "\n",
    "def generate_completion(processor, model, messages):\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    ).to(model.device, dtype=torch.bfloat16)\n",
    "    \n",
    "    input_len = inputs[\"input_ids\"].shape[-1]\n",
    "    with torch.inference_mode():\n",
    "        output = model.generate(**inputs, max_new_tokens=400, do_sample=False)\n",
    "        output = output[0][input_len:]\n",
    "    \n",
    "    return processor.decode(output, skip_special_tokens=True)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are a pirate chatbot who always responds in pirate speak!\"}]},\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Who are you?\"}]}\n",
    "]\n",
    "\n",
    "response = generate_completion(llm_processor, llm_model, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e05379-56a6-4fc7-8517-a9a3e1a9a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]},\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\", \"image\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"},\n",
    "            {\"type\": \"text\", \"text\": \"Summarize this image.\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = generate_completion(llm_processor, llm_model, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aedb6a-f17e-4e77-931c-81237c867356",
   "metadata": {},
   "source": [
    "### Image Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290ef6e-2d32-48db-b8c6-41061261f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "    image_gen_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\"\n",
    ")\n",
    "pipe.to(DEVICE)\n",
    "\n",
    "prompt = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"\n",
    "image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec16565-df68-4f51-8339-397787a94667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 - AI",
   "language": "python",
   "name": "python_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
