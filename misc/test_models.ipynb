{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bccd8-b63d-480e-8f9b-e6022a36272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login, snapshot_download\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model_id = \"BAAI/bge-m3\"\n",
    "reranker_model_id = \"BAAI/bge-reranker-v2-m3\"\n",
    "llm_model_id = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "vision_llm_model_id = \"microsoft/Phi-3-vision-128k-instruct\"\n",
    "image_gen_model_id = \"stabilityai/sdxl-turbo\"\n",
    "DEVICE = \"cuda:0\"\n",
    "DOWNLOAD_REPOS = False\n",
    "\n",
    "if DOWNLOAD_REPOS:\n",
    "    # Saved to ~/.cache/huggingface/hub\n",
    "    load_dotenv()\n",
    "    login(token=os.getenv(\"HF_TOKEN\"))\n",
    "    snapshot_download(embed_model_id)\n",
    "    snapshot_download(reranker_model_id)\n",
    "    snapshot_download(llm_model_id)\n",
    "    snapshot_download(vision_llm_model_id)\n",
    "    snapshot_download(image_gen_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae51b9a-c580-4f5d-9116-b51c4d74e53e",
   "metadata": {},
   "source": [
    "### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045e3c3-4511-494c-addf-ecd4c4960d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer(embed_model_id).to(DEVICE)\n",
    "\n",
    "def get_embedding(model, text):\n",
    "    if not isinstance(text, list):\n",
    "        text = [text]\n",
    "    return model.encode(text)[0]\n",
    "\n",
    "sentence = \"This framework generates embeddings for each input sentence\"\n",
    "embedding = get_embedding(embed_model, sentence)\n",
    "print(len(embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5c7d6-af71-4171-b005-b24500b33709",
   "metadata": {},
   "source": [
    "### Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343bf24-5c3d-4ff8-bf7f-19a4c03729cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model_id)\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(reranker_model_id).to(DEVICE)\n",
    "reranker_model.eval()\n",
    "\n",
    "def get_rerank_scores(tokenizer, model, pairs):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            pairs, padding=True, truncation=True, return_tensors='pt', max_length=512\n",
    "        ).to(model.device)\n",
    "        scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    return scores.tolist()\n",
    "\n",
    "pairs = [[\"what is a panda?\", \"hi\"], [\"what is a panda?\", \"The giant panda is a bear species endemic to China.\"]]\n",
    "scores = get_rerank_scores(reranker_tokenizer, reranker_model, pairs)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9efea9-752d-4abf-a2ff-9e259a61b52a",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210eea72-2fff-4f8e-aa67-98f574da6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_model_id,\n",
    "    device_map=DEVICE,\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.6,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "def generate_text(pipeline, generation_args, messages):\n",
    "    output = pipe(messages, **generation_args)\n",
    "    return output[0][\"generated_text\"]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
    "]\n",
    "\n",
    "response = generate_text(pipeline, generation_args, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509759f-8871-4658-bb16-e2fc9d021157",
   "metadata": {},
   "source": [
    "### Vision Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4caaf-d1fb-49a2-b9e6-f674a156e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoProcessor\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    vision_llm_model_id,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    vision_llm_model_id,\n",
    "    device_map=DEVICE,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=\"auto\",\n",
    "    # _attn_implementation=\"flash_attention_2\",\n",
    "    _attn_implementation=\"eager\"\n",
    ")\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 500,\n",
    "    \"temperature\": 0.6,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "def generate_vision_text(processor, model, generation_args, messages, images):\n",
    "    prompt = processor.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(DEVICE)\n",
    "    generate_ids = model.generate(**inputs, eos_token_id=processor.tokenizer.eos_token_id, **generation_args)\n",
    "    generate_ids = generate_ids[:, inputs[\"input_ids\"].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "    return response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"<|image_1|>\\nWhat is shown in this image?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"In this image, we can see the city of New York, and more specifically the Statue of Liberty.\"},\n",
    "    {\"role\": \"user\", \"content\": \"<|image_2|>\\nAnd how about this image?\"}\n",
    "] \n",
    "image1 = load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")\n",
    "image2 = load_image(\"https://cdn.britannica.com/59/94459-050-DBA42467/Skyline-Chicago.jpg\")\n",
    "images = [image1, image2]\n",
    "\n",
    "response = generate_vision_text(processor, model, generation_args, messages, images)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aedb6a-f17e-4e77-931c-81237c867356",
   "metadata": {},
   "source": [
    "### Image Generation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290ef6e-2d32-48db-b8c6-41061261f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "    image_gen_model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\"\n",
    ")\n",
    "pipe.to(DEVICE)\n",
    "\n",
    "prompt = \"A cinematic shot of a baby racoon wearing an intricate italian priest robe.\"\n",
    "image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec16565-df68-4f51-8339-397787a94667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 - AI",
   "language": "python",
   "name": "python_ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
